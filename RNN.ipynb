{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import json\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.88079708 1.         0.98201379]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "print(sigmoid(np.array([1,2,22,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0320586  0.08714432 0.23688282 0.64391426]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x/exp_x.sum(axis=0)\n",
    "\n",
    "print(softmax(np.array([2,3,4,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_data(jsonfile, csvfile):\n",
    "    file = open(jsonfile)\n",
    "    data = json.load(file)\n",
    "    \n",
    "    f = csv.writer(open(csvfile, 'w'))\n",
    "    f.writerow([\"emotion\",\"utterance\"])\n",
    "    \n",
    "    for item in data:\n",
    "        for line in item:\n",
    "            f.writerow([line['emotion'],line['utterance']])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_data('DataSets/Friends/friends_train.json', 'DataSets/Friends/textData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "regex = re.compile('[^a-zA-Z\\' ]')\n",
    "\n",
    "def cleaner(string):\n",
    "    #string = regex.sub('',string)\n",
    "    string = string.translate({ord(i): None for i in '!.,&%#@?;\\\\'})\n",
    "    string = string.replace('-', ' ')\n",
    "    try:\n",
    "        w = string.lower().split()\n",
    "    except:\n",
    "        return \"NAW\"\n",
    "    w = [p.lower() for p in w]\n",
    "    \n",
    "    #w = [lemmatizer.lemmatize(word) for word in w]\n",
    "    string = \" \".join(w)\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(csvfile):\n",
    "    file = pd.read_csv(csvfile)\n",
    "    cols = ['emotion', 'utterance']\n",
    "    file = file[cols]\n",
    "    file['emotion_id'] = file['emotion'].factorize()[0]\n",
    "    file['utterance'] = [cleaner(sent) for sent in file['utterance']]\n",
    "    file = file[pd.notnull(file['utterance'])]\n",
    "    return file['utterance'], file['emotion_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        also i was the point person on my companys tr...\n",
      "1                          you mustve had your hands full\n",
      "2                                    that i did that i did\n",
      "3             so lets talk a little bit about your duties\n",
      "4                                      my duties all right\n",
      "5        now youll be heading a whole division so you...\n",
      "6                                                    i see\n",
      "7        but therell be perhaps 30 people under you so...\n",
      "8                                             good to know\n",
      "9                                    we can go into detail\n",
      "10                                   no dont i beg of you\n",
      "11       all right then well have a definite answer fo...\n",
      "12                                                  really\n",
      "13                  absolutely you can relax you did great\n",
      "14       but then who the waitress i went out with last...\n",
      "15                                      you know forget it\n",
      "16           no no no no no who who were you talking about\n",
      "17                  no i i i i don't i actually don't know\n",
      "18                                                      ok\n",
      "19                                          all right well\n",
      "20       i'm gonna see if i can get a room for the nigh...\n",
      "21                                      i'll see you later\n",
      "22                                               yeah sure\n",
      "23                                                 hey mon\n",
      "24         hey hey hey you wanna hear something that sucks\n",
      "25                                               do i ever\n",
      "26                 chris says theyre closing down the bar\n",
      "27                                                  no way\n",
      "28       yeah apparently theyre turning it into some k...\n",
      "29             just coffee where are we gonna hang out now\n",
      "                               ...                        \n",
      "10531                               the money will turn up\n",
      "10532            people will always wanna invest in movies\n",
      "10533                           hey you're not rich are ya\n",
      "10534                                                   no\n",
      "10535    eh worth a shot look joey let me know where yo...\n",
      "10536                       hey pal are you joey tribbiani\n",
      "10537                                                 yeah\n",
      "10538                                these got left for ya\n",
      "10539             thanks congratulations on your big break\n",
      "10540                  rachel do you have any muffins left\n",
      "10541                             yeah i forget which ones\n",
      "10542    oh you're busy that's ok i'll get it anybody e...\n",
      "10543                                                  hey\n",
      "10544                                                  hey\n",
      "10545                                      so how was joan\n",
      "10546                                  i broke up with her\n",
      "10547       dont tell me because of the big nostril thing\n",
      "10548    they were huge when she sneezed bats flew out ...\n",
      "10549                      come on they were not that huge\n",
      "10550    i'm tellin' you she leaned back i could see he...\n",
      "10551    how many perfectly fine women are you gonna re...\n",
      "10552                                      hold it hold it\n",
      "10553               i gotta side with chandler on this one\n",
      "10554    when i first moved to the city i went out a co...\n",
      "10555                                      it made me nuts\n",
      "10556                                            you or me\n",
      "10557      i got it uh joey women don't have adam's apples\n",
      "10558                   you guys are messing with me right\n",
      "10559                                                 yeah\n",
      "10560    that was a good one for a second there i was l...\n",
      "Name: utterance, Length: 10561, dtype: object 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        1\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        0\n",
      "9        0\n",
      "10       2\n",
      "11       0\n",
      "12       1\n",
      "13       0\n",
      "14       1\n",
      "15       3\n",
      "16       1\n",
      "17       3\n",
      "18       0\n",
      "19       0\n",
      "20       3\n",
      "21       3\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       4\n",
      "26       5\n",
      "27       1\n",
      "28       0\n",
      "29       3\n",
      "        ..\n",
      "10531    0\n",
      "10532    0\n",
      "10533    0\n",
      "10534    6\n",
      "10535    0\n",
      "10536    0\n",
      "10537    0\n",
      "10538    0\n",
      "10539    3\n",
      "10540    0\n",
      "10541    0\n",
      "10542    0\n",
      "10543    0\n",
      "10544    4\n",
      "10545    0\n",
      "10546    0\n",
      "10547    1\n",
      "10548    7\n",
      "10549    0\n",
      "10550    7\n",
      "10551    1\n",
      "10552    0\n",
      "10553    0\n",
      "10554    7\n",
      "10555    7\n",
      "10556    0\n",
      "10557    3\n",
      "10558    1\n",
      "10559    0\n",
      "10560    3\n",
      "Name: emotion_id, Length: 10561, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X,Y = prepare_data('DataSets/Friends/textData.csv')\n",
    "print(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x7f3e41529548>\n"
     ]
    }
   ],
   "source": [
    "print(zip(X, Y))\n",
    "f = csv.writer(open('DataSets/Friends/ProcessedData.csv', 'w'))\n",
    "f.writerow([\"emotion\",\"utterance\"])\n",
    "    \n",
    "for item in zip(Y,X):\n",
    "    f.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(embed):\n",
    "    with open(embed, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        j=0\n",
    "        for line in f:\n",
    "            j+=1\n",
    "            line = line.strip().split()\n",
    "            word = line[0]\n",
    "            words.add(word)\n",
    "            word_to_vec_map[word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "        i=1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        index_to_vec = np.zeros((j,50))\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            index_to_vec[i-1,:] = word_to_vec_map[w]\n",
    "            i+=1\n",
    "        return j, words_to_index, index_to_words, word_to_vec_map, index_to_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words, words_to_index, index_to_words, word_to_vec_map, index_to_vec = read_glove_vecs('DataSets/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "maxi = 0\n",
    "for p in X:\n",
    "    w = p.lower().split()\n",
    "    j=0\n",
    "    for i in w:\n",
    "        try:\n",
    "            a = word_to_vec_map[i]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        j+=1\n",
    "    maxi = max(j,maxi)\n",
    "\n",
    "print(maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_mat(X):\n",
    "    Xmat = np.zeros((X.shape[0],50))\n",
    "    for i in range(X.shape[0]):\n",
    "        try:\n",
    "            words = X[i].lower().split()\n",
    "        except:\n",
    "            continue\n",
    "        j=0\n",
    "        for word in words:\n",
    "            try:\n",
    "                Xmat[i,j] = words_to_index[word]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            j+=1\n",
    "            if j>49:\n",
    "                break\n",
    "    return Xmat  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10561, 50)\n"
     ]
    }
   ],
   "source": [
    "Xmat = get_X_mat(X)\n",
    "print(Xmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, RNN, Input, Dropout, LSTM, Activation, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10561, 8)\n"
     ]
    }
   ],
   "source": [
    "Ymat = to_categorical(Y)\n",
    "print(Ymat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_Model_Keras(input_shape):\n",
    "    inputs = Input(shape=(input_shape), dtype=np.float32)\n",
    "    X = Embedding(400000,50,weights=[index_to_vec], input_length=50)(inputs)\n",
    "    X = LSTM(128)(X)\n",
    "    X = Dense(8, activation='softmax')(X)\n",
    "    model = Model(inputs=inputs, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 50, 50)            20000000  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 20,092,680\n",
      "Trainable params: 20,092,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN_Model_Keras((50,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = Adam(lr=0.005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=ad, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  830/10561 [=>............................] - ETA: 2:45 - loss: nan - acc: 0.4819"
     ]
    }
   ],
   "source": [
    "model.fit(Xmat, Ymat, epochs = 25, batch_size = 5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file = pd.read_csv('Project/DataSets/CompProcessedDataDev.csv')\n",
    "cols = ['emotion', 'utterance']\n",
    "dev_file = dev_file[pd.notnull(dev_file['utterance'])]\n",
    "X_test = dev_file['utterance']\n",
    "Y_test = dev_file['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "(972, 50, 50)\n",
      "(972, 8)\n"
     ]
    }
   ],
   "source": [
    "print(type(X[0]))\n",
    "Xmat_test = get_X_mat(X_test)\n",
    "print(Xmat_test.shape)\n",
    "Ymat_test = to_categorical(Y_test)\n",
    "print(Ymat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972/972 [==============================] - 1s 1ms/step\n",
      "3.3514347164719194\n",
      "0.33436214004033876\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(Xmat_test, Ymat_test)\n",
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
